{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89794718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import opencc\n",
    "from google import genai\n",
    "from google.genai import types as gtypes\n",
    "\n",
    "from ai_storyteller.music_generation.diffrhythm import DiffRhythm\n",
    "from ai_storyteller.utils.env_utils import get_env_var\n",
    "from ai_storyteller.utils.text_utils import clean_lyric_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = get_env_var(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ade603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DiffRhythm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ec096",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.generate_music(\n",
    "    lrc_path=\"../../data/music_generation/lrc/eg_en_full.lrc\",\n",
    "    ref_audio_path=\"../../data/music_generation/music/snoozy beats - Feel the Glow.mp3\",\n",
    "    output_dir=\"./output\",\n",
    "    output_file_name=\"sample.wav\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388e8cb",
   "metadata": {},
   "source": [
    "# Generate lyrics from a children's story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58974248",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/stories/the_wolf_and_the_seven_kids/story.json\") as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000eff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = data[\"pages\"]\n",
    "text = []\n",
    "for page in pages:\n",
    "    text.append(pages[page][\"text\"].strip())\n",
    "text = \"\\n\".join(text).strip()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca17537",
   "metadata": {},
   "source": [
    "## Prepare prompt for lyric generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc686db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_lyrics_from_story_prompt = \"\"\"\\\n",
    "根據以下故事生成歌詞，這首歌長度為{seconds}秒\n",
    "格式應該是 .lrc，例如：\n",
    "\n",
    "```\n",
    "[00:00.00]歌詞內容\n",
    "[00:01.00]歌詞內容\n",
    "...\n",
    "```\n",
    "除了歌詞以外，其他的內容都不需要，中間不能有空行，如果故事的內容是中文，請用中文生成歌詞，如果故事的內容是英文，請用英文生成歌詞。\n",
    "\n",
    "故事：\n",
    "```\n",
    "{story}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "filled_gen_lyrics_from_story_prompt = gen_lyrics_from_story_prompt.format(\n",
    "    story=text, seconds=95\n",
    ")\n",
    "print(filled_gen_lyrics_from_story_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f214bc",
   "metadata": {},
   "source": [
    "## Option 1. Generate using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.models.generate_content(\n",
    "    model=model,\n",
    "    contents=filled_gen_lyrics_from_story_prompt,\n",
    ")\n",
    "lyrics = res.text\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac64bea",
   "metadata": {},
   "source": [
    "## Option 2. Generate using HuggingChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "huggingchat_api_key = get_env_var(\"HUGGINGCHAT_API_KEY\")\n",
    "client = InferenceClient(\n",
    "    provider=\"novita\",\n",
    "    api_key=huggingchat_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"{filled_gen_lyrics_from_story_prompt}/nothink\"}\n",
    "]\n",
    "res = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",\n",
    "    messages=messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=8192,\n",
    "    top_p=0.7,\n",
    ")\n",
    "lyrics = res.choices[0].message.content\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d56c2",
   "metadata": {},
   "source": [
    "## Option 3. Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,  # pyright: ignore[reportPrivateImportUsage]\n",
    "    AutoTokenizer,  # pyright: ignore[reportPrivateImportUsage]\n",
    "    BitsAndBytesConfig,  # pyright: ignore[reportPrivateImportUsage]\n",
    ")\n",
    "\n",
    "model_name = \"Qwen/Qwen8-4B\"\n",
    "# model_name = \"Qwen/Qwen3-4B\"  # 如果遇到沒有VRAM的問題，可以試試這個模型（）\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de278e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": f\"{filled_gen_lyrics_from_story_prompt}\"}]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False,  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=32768)\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]) :].tolist()\n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\n",
    "    \"\\n\"\n",
    ")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)\n",
    "lyrics = content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ca670",
   "metadata": {},
   "source": [
    "## Clean lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b90f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = clean_lyric_lines(lyrics)\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61643893",
   "metadata": {},
   "source": [
    "## Simplified Chinese seems to work better, so we'll convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec17f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2s = opencc.OpenCC(\"t2s.json\")\n",
    "lyrics = t2s.convert(lyrics)\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55cb1b5",
   "metadata": {},
   "source": [
    "## Save lyrics to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/lyrics.lrc\", \"w\") as f:\n",
    "    f.write(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc5043",
   "metadata": {},
   "source": [
    "# Generate a song from the lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1316e80",
   "metadata": {},
   "source": [
    "## Using reference audio\n",
    "\n",
    "There are other samples in `data/music_generation/music`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef90f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = list(Path(\"../../data/music_generation/music\").glob(\"*.mp3\"))\n",
    "audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.generate_music(\n",
    "    lrc_path=\"/tmp/lyrics.lrc\",\n",
    "    ref_audio_path=audio_paths[0],\n",
    "    output_dir=\"./output\",\n",
    "    output_file_name=\"song_from_audio.wav\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d5216",
   "metadata": {},
   "source": [
    "## Using prompt seems to work better than using reference song\n",
    "\n",
    "Describe styles/scenes in words (e.g., `Jazzy Nightclub Vibe`, `Pop Emotional Piano` or `Indie folk ballad`, `coming-of-age themes`, `acoustic guitar picking with harmonica interludes`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.generate_music(\n",
    "    ref_prompt=\"Children's song\",\n",
    "    lrc_path=\"/tmp/lyrics.lrc\",\n",
    "    output_dir=\"./output\",\n",
    "    output_file_name=\"song_from_prompt.wav\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4a885",
   "metadata": {},
   "source": [
    "# Generate instruments only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83864527",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.generate_music(\n",
    "    ref_prompt=\"Children's song\",\n",
    "    output_dir=\"./output\",\n",
    "    output_file_name=\"instrumental_from_prompt.wav\",\n",
    "    instrumental_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96855559",
   "metadata": {},
   "source": [
    "# Identify instruments (with Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = get_env_var(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_instruments_prompt = \"你聽到了什麼樂器？請列出來\"\n",
    "with open(\"./output/instrumental_from_prompt.wav\", \"rb\") as f:\n",
    "    audio_bytes = f.read()\n",
    "\n",
    "res = client.models.generate_content(\n",
    "    model=model,\n",
    "    contents=[\n",
    "        identify_instruments_prompt,\n",
    "        gtypes.Part.from_bytes(\n",
    "            data=audio_bytes,\n",
    "            mime_type=\"audio/wav\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b37c1",
   "metadata": {},
   "source": [
    "# Exercise: Generate an instrumental using your own prompt\n",
    "\n",
    "* **分組。** 線上參與的同學可以自行組成小組。\n",
    "* **生成音樂：** 看看你的提示語可以多詳細，描述不同的音樂風格或特定樂器。測試模型的極限，試著給它一些挑戰。\n",
    "* **完成後，** 將檔案上傳到 Google Drive，檔名設為你們的組別編號 (線上組別也一樣)。\n",
    "* **組別請猜測試算表上順序下一組的歌曲（例如：第一組猜第二組，第二組猜第三組，...，最後一組猜第一組）。** 你們需要猜測那一首被分配到的歌曲用了什麼提示語。把你們猜的答案寫在試算表中你們組別的欄位下。\n",
    "* **線上的組別可以自由選擇任何組別的歌曲來猜測提示語。** 現場的組別在完成指定的猜測後，也可以自由猜測其他組的歌曲。把你們所有的猜測都寫進試算表。看看誰能猜得最接近、最準確！\n",
    "* **最後，** 原本生成歌曲的那一組要把他們用的提示語寫進試算表裡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351dd33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
